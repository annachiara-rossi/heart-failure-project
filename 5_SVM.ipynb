{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4734d2bc",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b783ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Eleonora\\\\statistical learning for healthcare data\\\\progetto'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "603de935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.random.seed(130298) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3381f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, auc, roc_curve, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8866d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a19b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer \n",
    "from fancyimpute import IterativeImputer, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40641104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06ae280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import auc, f1_score, recall_score, precision_score, roc_curve, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b202d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "935145c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2117f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(Y, final_pred):\n",
    "    fpr, tpr, _ = roc_curve(Y,final_pred)\n",
    "    AUC = auc(fpr, tpr)\n",
    "    f1 = f1_score(Y,final_pred)\n",
    "    rec = recall_score(Y,final_pred)\n",
    "    prec = precision_score(Y,final_pred)\n",
    "    print(f'AUC: {AUC}, F1: {f1}, Recall: {rec}, Precision: {prec}')\n",
    "    return [AUC, f1, rec, prec]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eee318",
   "metadata": {},
   "source": [
    "## Datasets definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2f1346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_name = 're.admission.within.6.months'\n",
    "\n",
    "# take the training set\n",
    "X_train = pd.read_csv('train_data_drugs.csv')\n",
    "X_train.set_index('inpatient.number', inplace = True)\n",
    "\n",
    "# separate the outcome\n",
    "Y_train = X_train[outcome_name].copy()\n",
    "X_train.drop(columns = outcome_name, inplace = True)\n",
    "\n",
    "# take the test set\n",
    "X_test = pd.read_csv('test_data_drugs.csv')\n",
    "X_test.set_index('inpatient.number', inplace = True)\n",
    "\n",
    "# separate the outcome\n",
    "Y_test = X_test[outcome_name].copy()\n",
    "X_test.drop(columns = outcome_name, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa8a62a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of traing set: (1567, 81) and of test set: (397, 81)\n"
     ]
    }
   ],
   "source": [
    "print(f'Size of traing set: {X_train.shape} and of test set: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26c41254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â take the lists of variables by type\n",
    "\n",
    "cat_columns = ['DestinationDischarge','admission.ward','admission.way','discharge.department',\n",
    "                       'type.of.heart.failure', 'NYHA.cardiac.function.classification', 'Killip.grade',\n",
    "                       'consciousness', 'ageCat']\n",
    "\n",
    "ordinal_columns = ['CCI.score', 'eye.opening','verbal.response', 'movement', 'GCS']\n",
    "\n",
    "not_continuous = cat_columns.copy()\n",
    "\n",
    "binary_columns = ['gender', 'diabetes', 'moderate.to.severe.chronic.kidney.disease',\n",
    "                  'return.to.emergency.department.within.6.months', 'diuretics',\n",
    "                  'hypertension', 'heart_failure', 'angina_etal', 'cholesterol_drug']\n",
    "\n",
    "not_continuous.extend(binary_columns)\n",
    "not_continuous.extend(ordinal_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ece53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each category we add its specification, needed to retreive columns after OneHotEcoding\n",
    "for cat in cat_columns:\n",
    "    X_train[cat] = cat + '_' + X_train[cat]\n",
    "    X_test[cat] = cat + '_' + X_test[cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73b623b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns = [col_name for col_name in X_train.columns if col_name not in not_continuous]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0b0a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_log = ['creatinine.enzymatic.method', 'urea', 'glomerular.filtration.rate', \n",
    "              'cystatin', 'lymphocyte.count', 'neutrophil.count',\n",
    "              'activated.partial.thromboplastin.time', 'prothrombin.time.ratio',\n",
    "              'glutamyltranspeptidase','indirect.bilirubin','alkaline.phosphatase',\n",
    "              'globulin','direct.bilirubin','cholesterol',\n",
    "              #'low.density.lipoprotein.cholesterol', # removed in the last corr analysis\n",
    "              'triglyceride']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8dd8c7",
   "metadata": {},
   "source": [
    "## Pipeline definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a59a64d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transf_stand(x):\n",
    "    \"Transform to log and standardize\"\n",
    "    x = np.log(x)\n",
    "    return (x - x.mean())/x.std()\n",
    "\n",
    "log_transformer = FunctionTransformer(log_transf_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ada7484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eleonora\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "C:\\Users\\Eleonora\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "        (\"log\", log_transformer, var_to_log),\n",
    "        (\"num\", StandardScaler(), list(set(cont_columns) - set(var_to_log))),     \n",
    "        (\"cat\", OneHotEncoder(), cat_columns)\n",
    "], remainder = 'passthrough') # do not modify columns not listed\n",
    "\n",
    "#total_pipeline = Pipeline(['stationarity', starting_pipeline])\n",
    "\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_test_prepared = full_pipeline.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e30e6762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of traing set: (1567, 107) and of test set: (397, 107)\n"
     ]
    }
   ],
   "source": [
    "print(f'Size of traing set: {X_train_prepared.shape} and of test set: {X_test_prepared.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90b40b08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/1567 with 1 missing, elapsed time: 1.688\n",
      "Imputing row 101/1567 with 3 missing, elapsed time: 1.695\n",
      "Imputing row 201/1567 with 4 missing, elapsed time: 1.702\n",
      "Imputing row 301/1567 with 1 missing, elapsed time: 1.711\n",
      "Imputing row 401/1567 with 17 missing, elapsed time: 1.718\n",
      "Imputing row 501/1567 with 5 missing, elapsed time: 1.727\n",
      "Imputing row 601/1567 with 5 missing, elapsed time: 1.734\n",
      "Imputing row 701/1567 with 6 missing, elapsed time: 1.742\n",
      "Imputing row 801/1567 with 2 missing, elapsed time: 1.751\n",
      "Imputing row 901/1567 with 1 missing, elapsed time: 1.758\n",
      "Imputing row 1001/1567 with 2 missing, elapsed time: 1.766\n",
      "Imputing row 1101/1567 with 2 missing, elapsed time: 1.775\n",
      "Imputing row 1201/1567 with 5 missing, elapsed time: 1.786\n",
      "Imputing row 1301/1567 with 2 missing, elapsed time: 1.794\n",
      "Imputing row 1401/1567 with 5 missing, elapsed time: 1.802\n",
      "Imputing row 1501/1567 with 1 missing, elapsed time: 1.809\n",
      "[KNN] Warning: 1567/167669 still missing after imputation, replacing with 0\n",
      "Imputing row 1/397 with 10 missing, elapsed time: 0.117\n",
      "Imputing row 101/397 with 5 missing, elapsed time: 0.123\n",
      "Imputing row 201/397 with 2 missing, elapsed time: 0.128\n",
      "Imputing row 301/397 with 1 missing, elapsed time: 0.137\n",
      "[KNN] Warning: 397/42479 still missing after imputation, replacing with 0\n"
     ]
    }
   ],
   "source": [
    "# imputation cannot be done inside the Pipeline because the method 'transform' is missing\n",
    "\n",
    "knn_imputer = KNN()\n",
    "X_train_prepared = knn_imputer.fit_transform(X_train_prepared)\n",
    "X_test_prepared = knn_imputer.fit_transform(X_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e4c3d47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of traing set: (1567, 107) and of test set: (397, 107)\n"
     ]
    }
   ],
   "source": [
    "print(f'Size of traing set: {X_train_prepared.shape} and of test set: {X_test_prepared.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fb540b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the columns names\n",
    "features_names = ['body.temperature', 'pulse', 'respiration', 'systolic.blood.pressure',\n",
    "                  'diastolic.blood.pressure', 'weight', 'BMI', 'fio2',\n",
    "                  'left.ventricular.end.diastolic.diameter.LV', 'creatinine.enzymatic.method',\n",
    "                  'urea', 'uric.acid', 'glomerular.filtration.rate', 'cystatin', 'monocyte.count',\n",
    "                  'red.blood.cell', 'coefficient.of.variation.of.red.blood.cell.distribution.width',\n",
    "                  'standard.deviation.of.red.blood.cell.distribution.width', 'mean.corpuscular.volume', \n",
    "                  'lymphocyte.count', 'mean.hemoglobin.concentration', 'mean.platelet.volume',\n",
    "                  'eosinophil.count', 'hemoglobin', 'platelet', 'platelet.distribution.width',\n",
    "                  'neutrophil.count', 'D.dimer', 'activated.partial.thromboplastin.time',\n",
    "                  'thrombin.time', 'prothrombin.activity', 'prothrombin.time.ratio', 'fibrinogen',\n",
    "                  'high.sensitivity.troponin', 'carbon.dioxide.binding.capacity', 'potassium', \n",
    "                  'chloride', 'sodium', 'glutamic.oxaloacetic.transaminase', 'creatine.kinase',\n",
    "                  'creatine.kinase.isoenzyme', 'lactate.dehydrogenase', 'brain.natriuretic.peptide',\n",
    "                  'nucleotidase', 'fucosidase', 'albumin', 'white.globulin.ratio',\n",
    "                  'glutamyltranspeptidase', 'glutamic.pyruvic.transaminase', 'indirect.bilirubin',\n",
    "                  'alkaline.phosphatase', 'globulin', 'direct.bilirubin', 'total.bile.acid',\n",
    "                  'total.protein', 'cholesterol', #'low.density.lipoprotein.cholesterol',\n",
    "                  'triglyceride', 'high.density.lipoprotein.cholesterol', 'dischargeDay',\n",
    "                  'gender', 'diabetes', 'moderate.to.severe.chronic.kidney.disease',\n",
    "                  #'return.to.emergency.department.within.6.months',\n",
    "                  'diuretics', \n",
    "                  'hypertension', 'heart_failure', 'angina_etal', 'cholesterol_drug', \n",
    "                  'CCI.score', 'eye.opening', 'verbal.response', 'movement', 'GCS',\n",
    "                  'DestinationDischarge_HealthcareFacility', 'DestinationDischarge_Home',\n",
    "                  'admission.ward_Cardiology', 'admission.ward_GeneralWard', 'admission.ward_ICU',\n",
    "                  'admission.ward_Others', 'admission.way_Emergency', 'admission.way_NonEmergency',\n",
    "                  'discharge.department_Cardiology', 'discharge.department_GeneralWard',\n",
    "                  'discharge.department_ICU', 'discharge.department_Others',\n",
    "                  'type.of.heart.failure_Both', 'type.of.heart.failure_Left', 'type.of.heart.failure_Right',\n",
    "                  'NYHA.cardiac.function.classification_II', 'NYHA.cardiac.function.classification_III',\n",
    "                  'NYHA.cardiac.function.classification_IV', 'Killip.grade_I', 'Killip.grade_II',\n",
    "                  'Killip.grade_III', 'Killip.grade_IV', 'consciousness_Clear', 'consciousness_Nonresponsive',\n",
    "                  'consciousness_ResponsiveToPain', 'consciousness_ResponsiveToSound',\n",
    "                  'ageCat_(21,29]', 'ageCat_(29,39]', 'ageCat_(39,49]', 'ageCat_(49,59]',\n",
    "                  'ageCat_(59,69]', 'ageCat_(69,79]', 'ageCat_(79,89]', 'ageCat_(89,110]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb8714d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for idx,elem in enumerate(features_names):\n",
    "#    if elem == 'nan':\n",
    "#        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "586d459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_prepared = np.delete(X_train_prepared, idx, axis = 1)\n",
    "#X_test_prepared = np.delete(X_test_prepared, idx, axis = 1)\n",
    "\n",
    "# ADJUST THIS!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba01f21",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "500ebff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-weighted score: 0.5606718796218569 and stadard deviation: 0.027442772112927217\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "\n",
    "scores = cross_val_score(clf,X_train_prepared,Y_train,cv=10,scoring='f1_weighted')\n",
    "print(f'Mean F1-weighted score: {scores.mean()} and stadard deviation: {scores.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2449f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-weighted score: 0.6228722684625217 and stadard deviation: 0.02822839784352566\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(class_weight = 'balanced')\n",
    "\n",
    "scores = cross_val_score(clf,X_train_prepared,Y_train,cv=10,scoring='f1_weighted')\n",
    "print(f'Mean F1-weighted score: {scores.mean()} and stadard deviation: {scores.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53fca967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(Y, final_pred):\n",
    "    \"\"\"\n",
    "    Compute AUC, F1, Recall and Precision given the target and the model predictions\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(Y,final_pred)\n",
    "    AUC = auc(fpr, tpr)\n",
    "    f1 = f1_score(Y,final_pred)\n",
    "    rec = recall_score(Y,final_pred)\n",
    "    prec = precision_score(Y,final_pred)\n",
    "    #print(f'AUC: {AUC}, F1: {f1}, Recall: {rec}, Precision: {prec}')\n",
    "    return [AUC, f1, rec, prec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a56992dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_svm_model(X_train, y_train, svm_clf, scoring):\n",
    "    \"\"\"\n",
    "    Performs a Randomized Grid Search trying to maximize the scoring defined \n",
    "    svm_clf can be the vanilla model svm.SVC() with any added specification\n",
    "    \"\"\"\n",
    "    param_grid = {'C': np.linspace(0.5, 10, 100), 'gamma': np.logspace(-4, 1, 100)}\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "    grid = RandomizedSearchCV(svm_clf, param_grid, n_iter=10, scoring=scoring, cv=cv, random_state= 1)\n",
    "\n",
    "    grid.fit(X_train,y_train)\n",
    "    final_model = grid.best_estimator_\n",
    "    \n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51b89fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_testing(X_train, y_train, X_test, y_test, svm_clf, scoring):\n",
    "    \"\"\"\n",
    "    1) Find the best model through CV\n",
    "    2) Predict on test data\n",
    "    3) Evaluate AUC, F1, Recall and Precision\n",
    "    \"\"\"\n",
    "    final_model = final_svm_model(X_train, y_train, svm_clf, scoring)\n",
    "    final_predictions = final_model.predict(X_test)\n",
    "    metrics = compute_metrics(Y = y_test, final_pred = final_predictions)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9178e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c03dd354",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_1 = svm_testing(X_train_prepared, Y_train, X_test_prepared, Y_test, svm.SVC(),'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdde6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_2 = svm_testing(X_train_prepared, Y_train, X_test_prepared, Y_test, svm.SVC(),'f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a4d7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_3 = svm_testing(X_train_prepared, Y_train, X_test_prepared, Y_test, svm.SVC(class_weight = 'balanced'),'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f52c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_4 = svm_testing(X_train_prepared, Y_train, X_test_prepared, Y_test, svm.SVC(class_weight = 'balanced'),'f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39cd12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_5 = svm_testing(X_train_prepared, Y_train, X_test_prepared, Y_test, svm.SVC(class_weight = 'balanced'),'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "302ba903",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_6 = svm_testing(X_train_prepared, Y_train, X_test_prepared, Y_test, svm.SVC(class_weight = 'balanced'),'balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81cbc8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_7 = svm_testing(X_train_prepared, Y_train, X_test_prepared, Y_test, svm.SVC(class_weight = 'balanced'),'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d49e63e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM, F1-score</th>\n",
       "      <td>0.598097</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.560748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM, f1_weighted</th>\n",
       "      <td>0.598097</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.560748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM(balanced), f1</th>\n",
       "      <td>0.586032</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.525974</td>\n",
       "      <td>0.485030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM(balanced), f1_weighted</th>\n",
       "      <td>0.598097</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.560748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM(balanced), recall</th>\n",
       "      <td>0.603455</td>\n",
       "      <td>0.530488</td>\n",
       "      <td>0.564935</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM(balanced), balanced_accuracy</th>\n",
       "      <td>0.607798</td>\n",
       "      <td>0.523962</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.515723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM(balanced), roc_auc</th>\n",
       "      <td>0.607798</td>\n",
       "      <td>0.523962</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.515723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       AUC  F1-score    Recall  Precision\n",
       "SVM, F1-score                     0.598097  0.459770  0.389610   0.560748\n",
       "SVM, f1_weighted                  0.598097  0.459770  0.389610   0.560748\n",
       "SVM(balanced), f1                 0.586032  0.504673  0.525974   0.485030\n",
       "SVM(balanced), f1_weighted        0.598097  0.459770  0.389610   0.560748\n",
       "SVM(balanced), recall             0.603455  0.530488  0.564935   0.500000\n",
       "SVM(balanced), balanced_accuracy  0.607798  0.523962  0.532468   0.515723\n",
       "SVM(balanced), roc_auc            0.607798  0.523962  0.532468   0.515723"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([metrics_1, metrics_2, metrics_3, metrics_4, metrics_5, metrics_6, metrics_7], \n",
    "             columns = ['AUC', 'F1-score', 'Recall', 'Precision'],\n",
    "             index = ['SVM, F1-score','SVM, f1_weighted','SVM(balanced), f1','SVM(balanced), f1_weighted',\n",
    "                     'SVM(balanced), recall','SVM(balanced), balanced_accuracy','SVM(balanced), roc_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725cc8b8",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "571f3cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators = 100)\n",
    "\n",
    "param_grid = {'base_estimator__max_depth': np.linspace(3,10,3).astype(int), \n",
    "              'base_estimator__min_samples_leaf': np.linspace(1,20,5).astype(int), \n",
    "              'base_estimator__min_samples_split': np.linspace(2,40,10).astype(int), \n",
    "              'base_estimator__min_impurity_decrease': np.linspace(0,0.4,10), \n",
    "              'base_estimator__max_leaf_nodes': np.linspace(2,20,5).astype(int)}\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "grid_clf = RandomizedSearchCV(clf, param_distributions = param_grid, n_iter=5, cv=cv) # if greater than 5 runtime is too high\n",
    "grid_clf.fit(X_train_prepared,Y_train)\n",
    "best_params_clf = grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7890f872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                         max_leaf_nodes=20,\n",
       "                                                         min_impurity_decrease=0.26666666666666666,\n",
       "                                                         min_samples_leaf=5,\n",
       "                                                         min_samples_split=27),\n",
       "                   n_estimators=100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(**best_params_clf)\n",
    "clf.fit(X_train_prepared,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b19c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
